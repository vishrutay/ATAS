{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes_on_filename(df_all, AWNS_par, AWS_par):\n",
    "    \"\"\"\n",
    "    Merge df_all with either AWNS_par or AWS_par based on matching file names, \n",
    "    adding columns in the same order as in AWNS_par or AWS_par, and inserting them right after 'File_Name'.\n",
    "\n",
    "    Parameters:\n",
    "    df_all (DataFrame): The main dataframe containing filenames with '.wav' extension.\n",
    "    AWNS_par (DataFrame): DataFrame containing the 'ID' column without the '.wav' extension.\n",
    "    AWS_par (DataFrame): Another DataFrame containing the 'ID' column without the '.wav' extension.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Updated df_all with matched rows from either AWNS_par or AWS_par.\n",
    "    \"\"\"\n",
    "\n",
    "    df_all_copy = df_all.copy()\n",
    "\n",
    "    # Loop through each row in df_all_copy\n",
    "    for i, row_1 in df_all_copy.iterrows():\n",
    "        filename_1 = row_1['File_Name']  \n",
    "        filename_no_ext = filename_1.rsplit('.', 1)[0]  # Remove the '.wav' extension\n",
    "        \n",
    "        # Check if the filename matches an entry in AWNS_par or AWS_par\n",
    "        matching_row_AWNS = AWNS_par[AWNS_par['ID'] == filename_no_ext]\n",
    "        matching_row_AWS = AWS_par[AWS_par['ID'] == filename_no_ext]\n",
    "        \n",
    "        idx_after_first_col = df_all_copy.columns.get_loc('File_Name') + 1  # Insert right after 'File_Name'\n",
    "\n",
    "        # If a match is found in AWNS_par\n",
    "        if not matching_row_AWNS.empty:\n",
    "            # Add columns in the same order as they appear in AWNS_par\n",
    "            for col in matching_row_AWNS.columns:\n",
    "                if col != 'ID':  # Skip 'ID' column\n",
    "                    if col not in df_all_copy.columns:\n",
    "                        # Insert the new column right after 'File_Name'\n",
    "                        df_all_copy.insert(idx_after_first_col, col, pd.NA)\n",
    "                        idx_after_first_col += 1  # Move to the next position\n",
    "                    df_all_copy.loc[i, col] = matching_row_AWNS[col].values[0]\n",
    "\n",
    "        # If a match is found in AWS_par\n",
    "        elif not matching_row_AWS.empty:\n",
    "            # Add columns in the same order as they appear in AWS_par\n",
    "            for col in matching_row_AWS.columns:\n",
    "                if col != 'ID':  # Skip 'ID' column\n",
    "                    if col not in df_all_copy.columns:\n",
    "                        # Insert the new column right after 'File_Name'\n",
    "                        df_all_copy.insert(idx_after_first_col, col, pd.NA)\n",
    "                        idx_after_first_col += 1  # Move to the next position\n",
    "                    df_all_copy.loc[i, col] = matching_row_AWS[col].values[0]\n",
    "\n",
    "    return df_all_copy\n",
    "\n",
    "# Define the function to process pauses and update the DataFrame\n",
    "def process_pause_durations(file_need, df, i, pause_threshold):\n",
    "    # Check if columns exist, if not, create them\n",
    "\n",
    "    # Add all event durations sequence-wise\n",
    "    if 'All_events_durations' not in df.columns:\n",
    "        df['All_events_durations'] = None\n",
    "    \n",
    "    if 'long_p_durations' not in df.columns:\n",
    "        df['long_p_durations'] = None\n",
    "    if 'short_p_durations' not in df.columns:\n",
    "        df['short_p_durations'] = None\n",
    "    if 'long_p_count' not in df.columns:\n",
    "        df['long_p_count'] = None\n",
    "    if 'short_p_count' not in df.columns:\n",
    "        df['short_p_count'] = None\n",
    "        \n",
    "    if 'long_p_durations_mean' not in df.columns:\n",
    "        df['long_p_durations_mean'] = None\n",
    "    if 'short_p_durations_mean' not in df.columns:\n",
    "        df['short_p_durations_mean'] = None\n",
    "    if 'long_p_durations_cv' not in df.columns:\n",
    "        df['long_p_durations_cv'] = None\n",
    "    if 'short_p_durations_cv' not in df.columns:\n",
    "        df['short_p_durations_cv'] = None\n",
    "    \n",
    "\n",
    "    # Load the corresponding CSV file\n",
    "    ddf = pd.read_csv(file_need)\n",
    "\n",
    "\n",
    "    # Identify long and short pauses\n",
    "    long_p = [idx for idx in ddf.index if (ddf[\"Labels\"][idx] == 'p') & (ddf[\"Time_diff\"][idx] >= pause_threshold)]\n",
    "    short_p = [idx for idx in ddf.index if (ddf[\"Labels\"][idx] == 'p') & (ddf[\"Time_diff\"][idx] < pause_threshold)]\n",
    "    \n",
    "\n",
    "    # Calculate long pause durations, means, and CV\n",
    "    long_p_dur = [ddf[\"Time_diff\"][idx] for idx in long_p]\n",
    "    if long_p_dur:  \n",
    "        long_p_mean = statistics.mean(long_p_dur)\n",
    "        long_p_cv = variation(long_p_dur)\n",
    "    else:\n",
    "        long_p_mean = 0\n",
    "        long_p_cv = 0\n",
    "\n",
    "    # Calculate short pause durations, means, and CV\n",
    "    short_p_dur = [ddf[\"Time_diff\"][idx] for idx in short_p]\n",
    "    if short_p_dur: \n",
    "        short_p_mean = statistics.mean(short_p_dur)\n",
    "        short_p_cv = variation(short_p_dur)\n",
    "    else:\n",
    "        short_p_mean = 0\n",
    "        short_p_cv = 0\n",
    "        \n",
    "    all_events_dur = ddf[\"Time_diff\"].values\n",
    "\n",
    "    pause_type = np.where(\n",
    "        (ddf['Labels'] == 'p') & (ddf['Time_diff'] >= pause_threshold), 2,   # First condition\n",
    "        np.where(\n",
    "            (ddf['Labels'] == 'p') & (ddf['Time_diff'] < pause_threshold), 1,  # Second condition\n",
    "            0  \n",
    "        )\n",
    "    )\n",
    "\n",
    "# Array corresponding to the conditions.\n",
    "\n",
    "\n",
    "    # Update the corresponding row in df with the processed pause data\n",
    "    df.at[i, 'All_events_durations'] = ','.join(map(str, all_events_dur))  # Convert to string\n",
    "    df.at[i, 'long_p_durations'] = ','.join(map(str, long_p_dur))          # Convert to string\n",
    "    df.at[i, 'short_p_durations'] = ','.join(map(str, short_p_dur))        # Convert to string\n",
    "    df.at[i,'Event_type'] = ','.join(map(str, pause_type))        # Convert to string\n",
    "    df.at[i, 'long_p_count'] = len(long_p_dur)\n",
    "    df.at[i, 'short_p_count'] = len(short_p_dur)\n",
    "    df.at[i, 'long_p_durations_mean'] = long_p_mean\n",
    "    df.at[i, 'short_p_durations_mean'] = short_p_mean\n",
    "    df.at[i, 'long_p_durations_cv'] = long_p_cv\n",
    "    df.at[i, 'short_p_durations_cv'] = short_p_cv\n",
    "    \n",
    "def calculate_speech_rate(df_all_1):\n",
    "    # Calculate speech rate for both AWS and AWNS participants\n",
    "    speech_rate_1 = df_all_1[\"Final_word_count\"] / df_all_1[\"Total_Duration_Clipped_s\"] * 60\n",
    "    df_all_1[\"Speech_Rate\"] = speech_rate_1\n",
    "\n",
    "\n",
    "def merge_ssi_scores(df_all_1, ssi_scores):\n",
    "    \"\"\"\n",
    "    Merge SSI scores for AWS participants into df_all_1.\n",
    "    ID in SSI corresponds to File_Name in df_all_1 but without the .wav extension.\n",
    "    \"\"\"\n",
    "    # Create a temporary column for matching (without modifying the original File_Name)\n",
    "    df_all_1['File_ID'] = df_all_1['File_Name'].str.replace('.wav', '', regex=False)\n",
    "    \n",
    "    # Merge the SSI scores with df_all_1 based on File_ID and ID in SSI scores\n",
    "    df_all_1 = pd.merge(df_all_1, ssi_scores, left_on='File_ID', right_on='ID', how='left')\n",
    "    \n",
    "    # Replace SSI scores with NaN for AWNS participants\n",
    "    df_all_1.loc[df_all_1['Group'] == 'AWNS', ssi_scores.columns.difference(['ID'])] = pd.NA\n",
    "\n",
    "    # Drop the temporary 'File_ID' column to keep the original data clean\n",
    "    df_all_1 = df_all_1.drop(columns=['File_ID'])\n",
    "\n",
    "    return df_all_1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
