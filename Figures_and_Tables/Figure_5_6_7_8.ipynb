{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae385a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statistics\n",
    "from scipy.stats import variation\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import mannwhitneyu, shapiro\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file with all participant details \n",
    "#(Includes - participant details, SSI_score details,Speech_rate, and long and short pause metrics)\n",
    "par_details = pd.read_csv('..../Stat_csv_files/AWNS_AWS_all_details.csv') #Change path as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945a8978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File_Name', 'Group', 'Age', 'Sex', 'Total_words_expected',\n",
       "       'Words_missing_at_end', 'Final_word_count', 'Speech Time Threshold_ms',\n",
       "       'Pause Time Threshold_ms', 'Percent_Pause', 'Percent_Speech',\n",
       "       'Total_Duration_Unclipped_s', 'Total_Duration_Clipped_s',\n",
       "       'Speech_Duration_s', 'Pause_Duration_s', 'Speech_Events',\n",
       "       'Pause_Events', 'Mean Speech_s', 'Std Dev Speech', 'CV Speech',\n",
       "       'Mean Pause_s', 'Std Dev Pause', 'CV Pause', 'All_events_durations',\n",
       "       'long_p_durations', 'short_p_durations', 'long_p_count',\n",
       "       'short_p_count', 'long_p_durations_mean', 'short_p_durations_mean',\n",
       "       'long_p_durations_cv', 'short_p_durations_cv', 'Event_type',\n",
       "       'Speech_Rate', 'ID', 'No_of_stuttered_syllables',\n",
       "       'No_of_total_syllables', 'Percent_syllables_stuttered', 'Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_details.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98e3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups_statistical_analysis(df, column_name, group_col, plot_title, y_label, \n",
    "                                        unit_conversion_factor=1, plot_figure=1, alternative='greater', \n",
    "                                        group_order='AWNS-AWS'):\n",
    "    \"\"\"\n",
    "    Compare AWS and AWNS groups statistically using Mann-Whitney U test, calculate means, and plot significance.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing participant data.\n",
    "    column_name (str): The metric column to be compared.\n",
    "    group_col (str): The column indicating the group ('AWS' or 'AWNS').\n",
    "    plot_title (str): Title for the plot.\n",
    "    y_label (str): Label for the y-axis.\n",
    "    unit_conversion_factor (float, optional): Factor to convert units (e.g., ms to s). Default is 1 (no conversion).\n",
    "    plot_figure (int, optional): 1 to plot the figure, 0 to skip plotting. Default is 1 (plot).\n",
    "    alternative (str, optional): Specify 'less', 'greater', or 'two-sided' for the Mann-Whitney U test alternative hypothesis.\n",
    "    group_order (str, optional): Order in which to compare groups for U calculation. Options are 'AWNS-AWS' (default) or 'AWS-AWNS'.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split data into AWS and AWNS groups\n",
    "    AWS_data = df[df[group_col] == 'AWS'][column_name] * unit_conversion_factor\n",
    "    AWNS_data = df[df[group_col] == 'AWNS'][column_name] * unit_conversion_factor\n",
    "\n",
    "    # Compute the mean for each group\n",
    "    AWS_mean = AWS_data.mean()\n",
    "    AWNS_mean = AWNS_data.mean()\n",
    "    \n",
    "    print(f\"Mean for AWS: {AWS_mean}\")\n",
    "    print(f\"Mean for AWNS: {AWNS_mean}\")\n",
    "\n",
    "    # Perform Shapiro-Wilk test for normality\n",
    "    AWS_shapiro = shapiro(AWS_data)\n",
    "    AWNS_shapiro = shapiro(AWNS_data)\n",
    "    print(f\"Shapiro-Wilk Test for AWS: {AWS_shapiro}\")\n",
    "    print(f\"Shapiro-Wilk Test for AWNS: {AWNS_shapiro}\")\n",
    "\n",
    "    # Perform Mann-Whitney U test based on specified group order\n",
    "    if group_order == 'AWNS-AWS':\n",
    "        U, p_value = mannwhitneyu(AWNS_data, AWS_data, alternative=alternative)\n",
    "        n1, n2 = len(AWNS_data), len(AWS_data)\n",
    "    elif group_order == 'AWS-AWNS':\n",
    "        U, p_value = mannwhitneyu(AWS_data, AWNS_data, alternative=alternative)\n",
    "        n1, n2 = len(AWS_data), len(AWNS_data)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid group_order. Use 'AWNS-AWS' or 'AWS-AWNS'.\")\n",
    "\n",
    "    print(f\"Mann-Whitney U Test: U-statistic = {U}, p-value = {p_value}\")\n",
    "\n",
    "    # Compute rank-biserial correlation using Wendt's formula, adjusted based on the 'alternative'\n",
    "    if alternative == 'greater':\n",
    "        r = (2 * U) / (n1 * n2) - 1\n",
    "    elif alternative == 'less' or alternative == 'two-sided':\n",
    "        r = 1 - (2 * U) / (n1 * n2)\n",
    "    \n",
    "    print(f\"Effect Size (Rank-Biserial Correlation): {r:.3f}\")\n",
    "\n",
    "    # Plot the results if requested\n",
    "    if plot_figure == 1:\n",
    "        data = [AWNS_data, AWS_data]\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        ax = fig.add_axes([0, 0, 1, 1])\n",
    "        bp = ax.boxplot(data, patch_artist=True)\n",
    "        \n",
    "        # Set colors for the box plots\n",
    "        colors = ['yellowgreen', 'cornflowerblue']\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        for median in bp['medians']:\n",
    "            median.set(color='black', linewidth=3)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title(plot_title, fontsize=20)\n",
    "        plt.xticks([1, 2], ['AWNS', 'AWS'], fontsize=20)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylabel(y_label, fontsize=20)\n",
    "        \n",
    "        # Significance level and annotation\n",
    "        bottom, top = ax.get_ylim()\n",
    "        y_range = top - bottom\n",
    "        bar_height = (y_range * 0.07 * -1) + top\n",
    "        \n",
    "        if p_value < 0.001:\n",
    "            sig_symbol = '***'\n",
    "        elif p_value < 0.01:\n",
    "            sig_symbol = '**'\n",
    "        elif p_value < 0.05:\n",
    "            sig_symbol = '*'\n",
    "        else:\n",
    "            sig_symbol = ''\n",
    "        \n",
    "        text_height = bar_height - (y_range * 0.1)\n",
    "        plt.text(1.5, text_height, sig_symbol, ha='center', va='bottom', color='k', fontsize=25)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7488074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'Speech_Rate', 'Group', 'Speech Rate', 'Time (s)', unit_conversion_factor=1, plot_figure=1, alternative='greater')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb2f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'Pause_Duration_s', 'Group', 'Total Pause Time', 'Time (s)', unit_conversion_factor=1, plot_figure=1, alternative='greater',group_order='AWS-AWNS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333919f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'Pause_Events', 'Group', 'Pause Count', 'No. of Pauses', unit_conversion_factor=1, plot_figure=0, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9d6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'Mean Pause_s', 'Group', 'Mean Pause Duration', 'Time (ms)', unit_conversion_factor=1000, plot_figure=1, alternative='greater',group_order='AWS-AWNS' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb74ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'Mean Speech_s', 'Group', 'Mean Vocal Duration', 'Time (ms)', unit_conversion_factor=1000, plot_figure=0, alternative='greater')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300735df",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'CV Pause', 'Group', 'Pause Duration Variability', 'Coefficient of Variation', unit_conversion_factor=1, plot_figure=0, alternative='less')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7392e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'CV Speech', 'Group', 'Vocal Duration Variability', 'Coefficient of Variation', unit_conversion_factor=1, plot_figure=0, alternative='less')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd68ee7",
   "metadata": {},
   "source": [
    "## Long and Short Pause Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2af33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'long_p_count', 'Group', 'Long Pause Count', 'No. of Pauses', unit_conversion_factor=1, plot_figure=1, alternative='two-sided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87955f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'short_p_count', 'Group', 'Short Pause Count', 'No. of Pauses', unit_conversion_factor=1, plot_figure=0, alternative='less')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1400003",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'long_p_durations_mean', 'Group', 'Mean Long Pauses Duration', 'Time (ms)', unit_conversion_factor=1000, plot_figure=0,alternative='two-sided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4f9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'short_p_durations_mean', 'Group', 'Mean Short Pauses Duration', 'Time (ms)', unit_conversion_factor=1000, plot_figure=1, alternative='less')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd461f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'long_p_durations_cv', 'Group', 'Long Pauses Duration Variability', 'Coefficient of Variability', unit_conversion_factor=1, plot_figure=1, alternative='less')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a1e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_groups_statistical_analysis(par_details, 'short_p_durations_cv', 'Group', 'Short Pauses Duration Variability', 'Coefficient of Variability', unit_conversion_factor=1, plot_figure=0, alternative='less')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59463468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benjamini-Hochberg procedure to control for the False Discovery Rate (FDR) amid multiple testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71c4366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def benjamini_hochberg(p_values, fdr=0.1):\n",
    "    \"\"\"\n",
    "    Perform the Benjamini-Hochberg procedure for controlling the false discovery rate.\n",
    "    \n",
    "    Parameters:\n",
    "    - p_values (list or np.array): Array of p-values to correct.\n",
    "    - fdr (float): Desired false discovery rate.\n",
    "    \n",
    "    Returns:\n",
    "    - np.array: Boolean array representing whether each test is significant.\n",
    "    \"\"\"\n",
    "    p_values = np.array(p_values)\n",
    "    n = len(p_values)\n",
    "    sorted_indices = np.argsort(p_values)\n",
    "    sorted_p_values = p_values[sorted_indices]\n",
    "    thresholds = fdr * np.arange(1, n + 1) / n\n",
    "    \n",
    "    reject = sorted_p_values <= thresholds\n",
    "    reject_max_index = np.where(reject)[0].max() if any(reject) else 0\n",
    "    reject[:reject_max_index + 1] = True\n",
    "    \n",
    "    corrected_sorted_indices = np.argsort(sorted_indices)\n",
    "    return reject[corrected_sorted_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [0.0026442424197612104, 0.03871779925087618, 0.0640899161502946, 0.041569327595409156, 0.35213730660438886, 0.5065832298410297, 0.003943189481594282, 0.030410340420505187, 0.48023395335819274, 0.6322436309019092, 0.022923590191909884, 0.12742047790214783, 0.7711412827862769]\n",
    "is_significant = benjamini_hochberg(p_values, fdr=0.1)\n",
    "\n",
    "print(f\"P-values: {p_values}\")\n",
    "print(f\"Significant at FDR=0.1: {is_significant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlations with % SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84248706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%SS\n",
    "aws_stuttered_percent = par_details[par_details['Group'] == 'AWS']['Percent_syllables_stuttered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a6ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def analyze_and_plot_correlation(x, y, x_label=\"X-axis\", y_label=\"Y-axis\", lp1=0.05, lp2=0.95):\n",
    "\n",
    "    # Calculate the Pearson correlation coefficient\n",
    "    corr_coeff, p_value = pearsonr(x, y)\n",
    "    print(\"Correlation coefficient:\", corr_coeff)\n",
    "    print(\"p-value:\", p_value)\n",
    "    \n",
    "    # Fit a linear regression model\n",
    "    x1 = np.array(x).reshape(-1, 1)  # Reshape for scikit-learn compatibility\n",
    "    model = LinearRegression().fit(x1, y)\n",
    "\n",
    "    # Create a scatter plot of the data\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(x, y, alpha=0.7)\n",
    "\n",
    "    # Add a regression line\n",
    "    plt.plot(np.unique(x), model.predict(np.unique(x).reshape(-1, 1)), color='black')\n",
    "\n",
    "    # Add axis labels\n",
    "    plt.xlabel(x_label, fontsize=20)\n",
    "    plt.ylabel(y_label, fontsize=20)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    # Add correlation coefficient and p-value inside the plot\n",
    "\n",
    "    plt.text(lp1, lp2, f\"r: {corr_coeff:.2f}, p-value: {'< .001' if p_value < 0.001 else f'{p_value:.3f}'.lstrip('0')}\", \n",
    "             fontsize=15, ha='left', va='top', fontweight='bold', style='italic', transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"correlation_coefficient\": corr_coeff,\n",
    "        \"p_value\": p_value,\n",
    "        \"regression_model\": model\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pause_aws = par_details[par_details['Group'] == 'AWS']['Pause_Duration_s']\n",
    "result1 = analyze_and_plot_correlation(total_pause_aws, aws_stuttered_percent, \n",
    "                                      x_label=\"Total Pause Time (sec)\", \n",
    "                                      y_label=\"%Syllables Stuttered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vocal_duration_aws = par_details[par_details['Group'] == 'AWS']['Mean Speech_s']\n",
    "result2 = analyze_and_plot_correlation(mean_vocal_duration_aws, aws_stuttered_percent, \n",
    "                                      x_label=\"Mean Vocal Duration (ms)\", \n",
    "                                      y_label=\"%Syllables Stuttered\",lp1 = 0.58,lp2 = 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_rate_aws = par_details[par_details['Group'] == 'AWS']['Speech_Rate']\n",
    "result3 = analyze_and_plot_correlation(speech_rate_aws, aws_stuttered_percent, \n",
    "                                      x_label=\"Speech Rate (wpm)\", \n",
    "                                      y_label=\"%Syllables Stuttered\", lp1 = 0.58,lp2 = 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_p_count_aws = par_details[par_details['Group'] == 'AWS']['long_p_count']\n",
    "result4 = analyze_and_plot_correlation(long_p_count_aws, aws_stuttered_percent, \n",
    "                                      x_label=\"Long Pause Count\", \n",
    "                                      y_label=\"%Syllables Stuttered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bcc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_p_count_aws = par_details[par_details['Group'] == 'AWS']['short_p_count']\n",
    "result5 = analyze_and_plot_correlation(short_p_count_aws, aws_stuttered_percent, \n",
    "                                      x_label=\"Short Pause Count\", \n",
    "                                      y_label=\"%Syllables Stuttered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combined Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_p_count_awns = par_details[par_details['Group'] == 'AWNS']['long_p_count']\n",
    "short_p_count_awns = par_details[par_details['Group'] == 'AWNS']['short_p_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c488d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_p_count_aws = np.array(long_p_count_aws)\n",
    "short_p_count_aws = np.array(short_p_count_aws)\n",
    "long_p_count_awns = np.array(long_p_count_awns)\n",
    "short_p_count_awns = np.array(short_p_count_awns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de6850",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p = [16, 24, 21, 19, 16, 33, 30, 24, 83, 59, 16, 32, 50, 22, 31, 21, 27]\n",
    "y_p = [32, 47, 35, 24, 32, 56, 70, 65, 169, 113, 25, 32, 99, 29, 55, 21, 37]\n",
    "\n",
    "xy_1 = [10,10,10,10,10,50,10,10,10,10,-20,10,10,-1,10,10,10]\n",
    "xy_2 = [80,50,50,300,50,70,50,50,10,50,130,50,50,240,50,10,50]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(short_p_count_awns,long_p_count_awns,color='yellowgreen', s=100,label='AWNS')\n",
    "\n",
    "plt.scatter(short_p_count_aws,long_p_count_aws,color= 'cornflowerblue', s=100,label='AWS')\n",
    "y_names = aws_stuttered_percent\n",
    "\n",
    "y_names= round(y_names,2)\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "    \n",
    "for i, txt in enumerate(y_names):\n",
    "    # Initialize the annotation position to the data point coordinates\n",
    "    x_pos, y_pos = short_p_count_aws[i], long_p_count_aws[i]\n",
    "    \n",
    "#     # Check for overlapping annotations\n",
    "    for j in range(i):\n",
    "        if abs(short_p_count_aws[i] - short_p_count_aws[j]) < 0.1 and abs(long_p_count_aws[i] - long_p_count_aws[j]) < 0.1:\n",
    "            # If the annotation overlaps with another annotation, adjust the position\n",
    "            x_pos += 0.5\n",
    "            y_pos += 0.5\n",
    "    \n",
    "    # Add the annotation to the plot with an arrow pointing to the data point\n",
    "    plt.annotate(txt, (x_p[i], y_p[i]),\n",
    "                xytext=(xy_1[i],xy_2[i]),\n",
    "                fontsize=15,textcoords='offset points',\n",
    "                ha='center',\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='black', lw=1,  shrinkA=0, shrinkB=0, relpos=(0,0)))\n",
    "\n",
    "plt.title('Long and Short Pauses (% Stuttered Syllables)',fontsize=20)\n",
    "plt.xlabel('Short Pause Count',fontsize=20)\n",
    "plt.ylabel('Long Pause Count',fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
